# HEP s/w: parallelism strikes back
IPHC Seminars, 2016-10-28

Sebastien Binet
CNRS/IN2P3/LPC-Clermont
https://github.com/sbinet
@0xbins
sebastien.binet@clermont.in2p3.fr

## Parallelism: why?

.image _figs/cpu-free-lunch.png 550 550

## (a brief) History of software in HEP

## 50's-90's: FORTRAN77

.play _code/hello.f.go /START OMIT/,/END OMIT/

	$ gfortran -c hello.f && gfortran -o hello hello.o
	$ ./hello
	Hello from FORTRAN

  - `FORTRAN77` is the **king**
  - 1964: **CERNLIB**
  - REAP (paper tape measurements), THRESH (geometry reconstruction)
  - SUMX, **HBOOK** (statistical analysis chain)
  - ZEBRA (memory management, I/O, ...)
  - GEANT3, **PAW**

## 90's-...: C++

.play _code/hello.cxx.go /START OMIT/,/END OMIT/

	$ c++ -o hello hello.cxx && ./hello
	Hello from C++

.image _figs/my-root6splash.png 190 190

  - object-oriented programming (OOP) is the cool kid on the block
  - **ROOT**, POOL, LHC++, AIDA, **Geant4**
  - `C++` takes roots in HEP

## 00's-...: python

.play _code/hello.py.go /START OMIT/,/END OMIT/

	$ python ./hello.py
	Hello from python

.image _figs/my-python-logo.png 100 250

  - `python` becomes the _de_ _facto_ scripting language in HEP
  - framework data-cards
  - analysis glue, (whole) analyses in `python`
  - **PyROOT**, rootpy
  - numpy, scipy, matplotlib, **IPython/Jupyter**

## Current software in a nutshell

  - **Generators**: generation of true particles from fondamental physics first principles
  - **Full** **Simulation**: tracking of all stable particles in magnetic field through the detector simulating interaction, recording energy deposition (**CPU** **intensive**)
  - **Reconstruction**: from real data, or from `Monte-Carlo` simulation data as above
  - **Fast** **Simulation**: parametric simulation, faster, coarser
  - **Analysis**: daily work of physicists, running on output of reconstruction to derive analysis specific information (**I/O** **intensive**)
  - everything in the same `C++` offline control framework (except analysis)

.image _figs/data-flux-summary-all.png 210 800

## 

  - `C++`: **slow** (very slow?) to compile/develop, **fast** to execute
  - `python`: **fast** development cycle (no compilation), **slow** to execute

.image _figs/xkcd-compiling.png 400 400

## Are those our only options ?

.image _figs/funfast-nogo.svg 500 _

## Meanwhile on the Hardware side...

## Moore's law

.image _figs/cpu-free-lunch.png 550 550

## The hardware/software contract

.image _figs/par-prog-old-days.png _ 850

## Hardware diversity: combining building blocks

.image _figs/par-prog-heterogeneous.png

## Moore's law

  - Moore's law still observed at the hardware level
  - **However** the _effective_ perceived computing power is mitigated

_"Easy_ _life"_ during the last 20-30 years:

  - Moore's law translated into **doubling** compute capacity every ~18 months (_via_ clock frequency)
  - **Concurrency** and **parallelism** necessary to efficiently harness the compute power of our new multi-core CPU architectures.

_But_ our current software isn't prepared for parallel/concurrent environments.

## Free lunch is over

.image _figs/head-on.png _ 900

## Interlude: concurrency & parallelism

## Interlude: Sequential, Concurrent & Parallel pizzas

## Pizza recipe

(**Disclaimer:** don't ever eat any pizza prepared or cooked by me.)

How to prepare a (sequential) pizza?

.code _code/make-pizza.f

Estimated time (1 chef, 1 pizza):

	xx-oooo-xxx-oo-###

How to make this faster?

## (Sequential) Pizza recipe

Tasks:

  - wash tomatoes and onions
  - cut tomatoes, onions
  - prepare pizza dough
  - put tomato sauce on top of pizza dough
  - toppings: put tomatoes, onions, ham and mozarella
  - (pre-)heat oven, bake
  - (cut, then eat)

Estimated time (1 chef, 1 pizza):

	xx-oooo-xxx-oo-###

## Concurrent pizzas - Parallel pizzas

Estimated time (1 chef, 1 kitchen, 2 pizzas):

	xx-oooo-xxx-oo-###-xx-oooo-xxx-oo-###

Estimated time (1 chef, 2 kitchens, 2 pizzas):

	xx-oooo-xxx-oo+###
	              +xx-oooo-xxx-oo-###

Estimated time (2 chefs, 1 kitchen, 2 pizzas):

	xx-xxx-+-xx-xxx-+
	       +###     +###
	oooo-oo+-oooo-oo+

Estimated time (2 chefs, 2 kitchens, 2 pizzas):

	xx-oooo-xxx-oo-###
	xx-oooo-xxx-oo-###

## Interlude: concurrency & parallelism

  - **Concurrency** is about _dealing_ with lots of things at once.
  - **Parallelism** is about _doing_ lots of things at once.
  - Not the same, but related.
  - Concurrency is about _structure_, parallelism is about _execution_.

.image _figs/conc-para.png 200 600

Concurrency is a way to structure a program by breaking it into pieces that can be executed independently.
Communication is the means to coordinate the independent executions.

## Concurrency vs Parallelism

Concurrency is about dealing with lots of things at once.
Parallelism is about doing lots of things at once.

Concurrency is about (program) **structure**.
Parallelism is about (program) **execution**.

.image _figs/conc-vs-par-prog.png 300 _

Concurrency is **not** parallelism, it's better :)

## Concurrency plus communication

Concurrency is a way to structure a program by breaking it into pieces that can be executed independently.

Communication is the means to coordinate the independent executions.

This is the Go model and (like Erlang and others) it's based on CSP:

C. A. R. Hoare: Communicating Sequential Processes (CACM 1978)

## Concurrency in HEP software

.image _figs/conc-level.png 600 400

## Concurrency in HEP software - II

.image _figs/levels-of-conc.png
.image _figs/gaudi-hive-2.png 250 350

## 

.image _figs/conc-para-mt-mp.png 600 1000

## Multi-processing

Launch _N_ instances of an application on a node with _N_ cores

  - re-use pre-existing code
  - _a_ _priori_ no required modification of pre-existing code
  - satisfactory _scalability_ with the number of cores

**But:**

  - resource requirements increase with the number of processes
  - memory footprint **increases**
  - as do other O/S (limited) resources (file descriptors, network sockets, ...)
  - scalability of **I/O** debatable when number of cores > ~100

## Multi-threading

.image _figs/mt-cxx.png

`C++11/14` libraries do help a bit:
- `std::lambda`, `std::thread`, `std::promise`
- (Intel) Threading Building Blocks
- ...

## Time for a new language ?

.image _figs/new-lang.png 600 800

## Candidates

  - python/pypy
  - FORTRAN-2008
  - Vala
  - Swift
  - Rust
  - Go
  - Chapel
  - Scala
  - Haskell
  - Clojure

## Let's Go

## What is Go ?

.play _code/hello.go

	$ go run hello.go
	Hello from Go

A nice language with a nice mascot.

.image _figs/golang-logo.png 200 400

## History

  - Project starts at Google in 2007 (by Griesemer, Pike, Thompson)
  - Open source release in November 2009
  - More than 700 contributors have joined the project
  - Version 1.0 release in March 2012
  - Version 1.1 release in May 2013
  - Version 1.2 release in December 2013
  - Version 1.3 release in June 2014
  - Version 1.4 release in December 2014
  - Version 1.5 release in August 2015
  - Version 1.6 release in February 2016
  - Version 1.7 release in August 2016

.link https://golang.org

## Elements of Go

  - Founding fathers: Russ Cox, Robert Griesemer, Ian Lance Taylor, Rob Pike, Ken Thompson

  - Concurrent, garbage-collected
  - An Open-source general progamming language (BSD-3)
  - feel of a **dynamic** **language**: limited verbosity thanks to the _type_ _inference_ _system_, map, slices
  - safety of a **static** **type** **system**
  - compiled down to machine language (so it is fast, goal is ~10% of C)
  - **object-oriented** but w/o classes, **builtin** **reflection**
  - first-class functions with **closures**
  - implicitly satisfied **interfaces**

Available on all major platforms (`Linux`, `Windows`, `macOS`, `Android`, `iOS`, ...) and for many architectures (`amd64`, `arm`, `arm64`, `i386`, `s390x`, `mips64`, ...)

## Concurrency: basic examples

## A boring function

We need an example to show the interesting properties of the concurrency primitives.
To avoid distraction, we make it a boring example.

.play _code/boring.go /START/,/STOP/

## Slightly less boring

Make the intervals between messages unpredictable (still under a second).

.play _code/lessboring.go /START/,/STOP/

## Running it

The boring function runs on forever, like a boring party guest.

.play _code/lessboring.go /^func.main/,$

## Ignoring it

The `go` statement runs the function as usual, but doesn't make the caller wait.

It launches a goroutine.

The functionality is analogous to the `&` on the end of a shell command.

.play _code/goboring.go 1,/^}/

## Ignoring it a little less

When `main` returns, the program exits and takes the boring function down with it.

We can hang around a little, and on the way show that both main and the launched goroutine are running.

.play _code/waitgoboring.go /func.main/,/^}/

## Goroutines

What is a goroutine? It's an independently executing function, launched by a go statement.

It has its own call stack, which grows and shrinks as required.

It's very cheap. It's practical to have thousands, even hundreds of thousands of goroutines.

It's not a thread.

There might be only one thread in a program with thousands of goroutines.

Instead, goroutines are multiplexed dynamically onto threads as needed to keep all the goroutines running.

But if you think of it as a very cheap thread, you won't be far off.

## Communication

Our boring examples cheated: the main function couldn't see the output from the other goroutine.

It was just printed to the screen, where we pretended we saw a conversation.

Real conversations require communication.

## Channels

A channel in Go provides a connection between two goroutines, allowing them to communicate.

.code _code/helpers.go /START1/,/STOP1/
.code _code/helpers.go /START2/,/STOP2/
.code _code/helpers.go /START3/,/STOP3/

## Using channels

A channel connects the main and boring goroutines so they can communicate.

.play _code/changoboring.go /START1/,/STOP1/
.code _code/changoboring.go /START2/,/STOP2/

## Synchronization

When the main function executes <–c, it will wait for a value to be sent.

Similarly, when the boring function executes c <– value, it waits for a receiver to be ready.

A sender and receiver must both be ready to play their part in the communication. Otherwise we wait until they are.

Thus channels both communicate and synchronize.

## The Go approach

Don't communicate by sharing memory, share memory by communicating.

## "Patterns"

## Generator: function that returns a channel

Channels are first-class values, just like strings or integers.

.play _code/generatorboring.go /START1/,/STOP1/
.code _code/generatorboring.go /START2/,/STOP2/

## Channels as a handle on a service

Our boring function returns a channel that lets us communicate with the boring service it provides.

We can have more instances of the service.

.play _code/generator2boring.go /START1/,/STOP1/

## Multiplexing

These programs make Joe and Ann count in lockstep.
We can instead use a fan-in function to let whosoever is ready talk.

.code _code/faninboring.go /START3/,/STOP3/
.play _code/faninboring.go /START1/,/STOP1/

## Fan-in

.image _figs/gophermegaphones.jpg

## Restoring sequencing

Send a channel on a channel, making goroutine wait its turn.

Receive all messages, then enable them again by sending on a private channel.

First we define a message type that contains a channel for the reply.

.code _code/sequenceboring.go /START0/,/STOP0/

## Restoring sequencing.

Each speaker must wait for a go-ahead.

.code _code/sequenceboring.go /START1/,/STOP1/
.code _code/sequenceboring.go /START2/,/STOP2/
.play _code/sequenceboring.go /START3/,/STOP3/

## Select

A control structure unique to concurrency.

The reason channels and goroutines are built into the language.

## Select

The select statement provides another way to handle multiple channels.
It's like a switch, but each case is a communication:

  - All channels are evaluated.
  - Selection blocks until one communication can proceed, which then does.
  - If multiple can proceed, select chooses pseudo-randomly.
  - A default clause, if present, executes immediately if no channel is ready.

.code _code/select.go /START0/,/STOP0/

## Fan-in again

Rewrite our original fanIn function. Only one goroutine is needed. Old:

.code _code/faninboring.go /START3/,/STOP3/

## Fan-in using select

Rewrite our original fanIn function. Only one goroutine is needed. New:

.play _code/selectboring.go /START3/,/STOP3/

## Timeout using select

The time.After function returns a channel that blocks for the specified duration.
After the interval, the channel delivers the current time, once.

.play _code/timeout.go /START1/,/STOP1/

## Timeout for whole conversation using select

Create the timer once, outside the loop, to time out the entire conversation.
(In the previous program, we had a timeout for each message.)

.play _code/timeoutall.go /START1/,/STOP1/

## Quit channel

We can turn this around and tell Joe to stop when we're tired of listening to him.

.code _code/quit.go /START1/,/STOP1/
.play _code/quit.go /START2/,/STOP2/

## Receive on quit channel

How do we know it's finished? Wait for it to tell us it's done: receive on the quit channel

.code _code/rcvquit.go /START1/,/STOP1/
.play _code/rcvquit.go /START2/,/STOP2/

## Daisy-chain

.play _code/daisy.go /func/,$

## Chinese whispers, gopher style

.image _figs/gophereartrumpet.jpg

## Conclusions

Goroutines and channels make it easy to express complex operations dealing with:

  - multiple inputs
  - multiple outputs
  - timeouts
  - failure

And they're fun to use.

## Real-world application?

OK, [Go](https://golang.org) is great.

And it's being used by [many companies](https://github.com/golang/go/wiki/GoUsers) (beside `Google`): Mozilla, New-York Times, CoreOS, Docker Inc., SpaceX, ...

But what about `HEP`? and `astro/cosmo`?

## fads

## fads

`fads` is a "FAst Detector Simulation" toolkit.

  - morally a translation of [C++-Delphes](https://cp3.irmp.ucl.ac.be/projects/delphes) into Go
  - uses [go-hep/fwk](https://github.com/go-hep/fwk) to expose, manage and harness concurrency into the usual `HEP` event loop (`initialize` | `process-events` | `finalize`)
  - uses [go-hep/hbook](https://github.com/go-hep/hbook) for histogramming, [go-hep/hepmc](htpps://github.com/go-hep/hepmc) for `HepMC` input/output

Code is on github (BSD-3):

.link https://github.com/go-hep/fwk
.link https://github.com/go-hep/fads

Documentation is served by [godoc.org](https://godoc.org):

.link https://godoc.org/github.com/go-hep/fwk
.link https://godoc.org/github.com/go-hep/fads

## go-hep/fads - Installation

As easy as:

	$ export GOPATH=$HOME/dev/gocode
	$ export PATH=$GOPATH/bin:$PATH

	$ go get github.com/go-hep/fads/...

Yes, with the ellipsis at the end, to also install sub-packages.

  - `go` `get` will recursively download and install all the packages that [go-hep/fads](https://github.com/go-hep/fads) depends on. (no `Makefile` needed)

## go-hep/fwk - Examples

	$ fwk-ex-tuto-1 -help
	Usage: fwk-ex-tuto1 [options]

	ex:
	 $ fwk-ex-tuto-1 -l=INFO -evtmax=-1

	options:
	  -evtmax=10: number of events to process
	  -l="INFO": message level (DEBUG|INFO|WARN|ERROR)
	  -nprocs=0: number of events to process concurrently

Runs 2 tasks.

.image _figs/fwk-ex1-dflow.png 200 200

## go-hep/fwk - Examples

	$ fwk-ex-tuto-1
	::: fwk-ex-tuto-1...
	t2                   INFO configure...
	t2                   INFO configure... [done]
	t1                   INFO configure ...
	t1                   INFO configure ... [done]
	t2                   INFO start...
	t1                   INFO start...
	app                  INFO >>> running evt=0...
	t1                   INFO proc... (id=0|0) => [10, 20]
	t2                   INFO proc... (id=0|0) => [10 -> 100]
	[...]
	app                  INFO >>> running evt=9...
	t1                   INFO proc... (id=9|0) => [10, 20]
	t2                   INFO proc... (id=9|0) => [10 -> 100]
	t2                   INFO stop...
	t1                   INFO stop...
	app                  INFO cpu: 654.064us
	app                  INFO mem: alloc:             62 kB
	app                  INFO mem: tot-alloc:         74 kB
	app                  INFO mem: n-mallocs:        407
	app                  INFO mem: n-frees:           60
	app                  INFO mem: gc-pauses:          0 ms
	::: fwk-ex-tuto-1... [done] (cpu=788.578us)

## go-hep/fwk - Concurrency

[fwk](https://github.com/go-hep/fwk) enables:
- event-level concurrency
- tasks-level concurrency

[fwk](https://github.com/go-hep/fwk) relies on [Go](https://golang.org)'s runtime to properly schedule _goroutines_.

For sub-task concurrency, users are by construction required to use [Go](https://golang.org)'s constructs (_goroutines_ and _channels_) so everything is consistent **and** the _runtime_ has the **complete** **picture**.

## go-hep/fads - real world use case

  - translated [C++-Delphes](https://cp3.irmp.ucl.ac.be/projects/delphes)' ATLAS data-card into Go
  - [go-hep/fads-app](https://github.com/go-hep/fads/blob/master/cmd/fads-app/main.go)
  - installation:

	$ go get github.com/go-hep/fads/cmd/fads-app
	$ fads-app -help
	Usage: fads-app [options] <hepmc-input-file>

	ex:
	 $ fads-app -l=INFO -evtmax=-1 ./testdata/hepmc.data

	options:
	  -cpu-prof=false: enable CPU profiling
	  -evtmax=-1: number of events to process
	  -l="INFO": log level (DEBUG|INFO|WARN|ERROR)
	  -nprocs=0: number of concurrent events to process

## go-hep/fads - components

  - a `HepMC` converter
  - particle propagator
  - calorimeter simulator
  - energy rescaler, momentum smearer
  - isolation
  - b-tagging, tau-tagging
  - jet-finder (reimplementation of FastJet in Go: [go-hep/fastjet](https://github.com/go-hep/fastjet))
  - histogram service (from [go-hep/fwk](https://github.com/go-hep/fwk))

Caveats:

  - no real persistency to speak of (_i.e.:_ `JSON`, `ASCII` and `Gob`)
  - jet clustering limited to N^3 (slowest and dumbest scheme of `C++-FastJet`)

## 

.image _figs/fads-dflow.png 600 600

## Results - testbenches

  - Linux: Intel(R) Core(TM)2 Duo CPU @ 2.53GHz, 4GB RAM, 2 cores
  - MacOSX-10.6: Intel(R) Xeon(R) CPU @ 2.27GHz, 172GB RAM, 16 cores
  - Linux: Intel(R) Xeon(R) CPU E5-2660 v2 @ 2.20GHz, 40 cores
  - Linux: Westmere E56xx/L56xx/X56xx (Nehalem-C) (3066.774 MHz), 20-cores, 40Gb RAM

## Linux (20 cores) testbench: memory (smaller==better)

.image _figs/linux-rss.png 550 800

## Linux (20 cores) testbench: event throughput (higher==better)

.image _figs/linux-cpu.png 550 800

## fads: Results & Conclusions

  - good RSS scaling
  - good CPU scaling

  - bit-by-bit matching physics results wrt `Delphes` (up to calorimetry)
  - no need to merge output files, less chaotic I/O, less I/O wait

Also addresses `C++` and `python` deficiencies:

  - code distribution
  - code installation
  - compilation/development speed
  - runtime speed
  - simple language

## Go in science

## Science-y packages

Even if `Go` is relatively new, support for general purpose scientific libraries is there and growing, thanks to the [gonum](https://github.com/gonum) community:

  - [gonum/blas](https://github.com/gonum/blas), a `go` based implementation of Basic Linear Algebra Subprograms
  - [gonum/lapack](https://github.com/gonum/lapack), a lapack implementation for `go`
  - [gonum/matrix](https://github.com/gonum/matrix), to work with matrices
  - [gonum/graph](https://github.com/gonum/graph), to work with graphs
  - [gonum/optimize](https://github.com/gonum/optimize), for finding the optimum value of functions
  - [gonum/integrate](https://github.com/gonum/integrate), provides routines for numerical integration
  - [gonum/diff](https://github.com/gonum/diff), for computing derivatives of a function
  - [gonum/stat](https://github.com/gonum/stat), for statistics and distributions
  - ...

## I/O & Making plots

Plotting data is also rather easy:

  - [gonum/plot](http://github.com/gonum/plot) (most of the plots seen earlier are made w/ `gonum/plot`)
  - [github.com/sbinet/go-gnuplot](https://github.com/sbinet/go-gnuplot)

I/O support for some formats:

  - [sbinet/npyio](https://github.com/sbinet/npyio): read/write support for [NumPy data files](http://docs.scipy.org/doc/numpy/neps/npy-format.html)
  - [ready-steady/mat](https://github.com/ready-steady/mat), [sbinet/matfio](https://github.com/sbinet/matfio): r/w support for [MATLAB files](http://www.mathworks.com/help/pdf_doc/matlab/apiext.pdf)
  - [sbinet/go-hdf5](https://github.com/sbinet/go-hdf5): access to [HDF5](https://www.hdfgroup.org/HDF5)

## Go for Data Science

A data science community is gathering around [github.com/gopherds](https://github.com/gopherds).

  - [gopherds/gophernotes](https://github.com/gopherds/gophernotes), a [Jupyter](http://jupyter.org) kernel for [Go](https://golang.org)
  - [gopherds/mybinder-go](https://github.com/gopherds/mybinder-go), a web-based Jupyter kernel for [Go](https://golang.org)
  - [gopherds/resources](https://github.com/gopherds/resources/tree/master/tooling): many resources for machine learning, classifiers, neural networks, ...

## Go in HEP

[go-hep.github.io](https://go-hep.github.io) gathers a few HEP-oriented packages:

  - [go-hep/fads](https://github.com/go-hep/fads): a fast detector simulation toolkit
  - [go-hep/fmom](https://github.com/go-hep/fmom): a 4-vectors library
  - [go-hep/fwk](https://github.com/go-hep/fwk): a concurrency-enabled framework
  - [go-hep/hbook](https://github.com/go-hep/hbook): histograms and n-tuples (WIP)
  - [go-hep/hplot](https://github.com/go-hep/hplot): interactive plotting (WIP)
  - [go-hep/hepmc](https://github.com/go-hep/hepmc): HepMC in pure Go (EDM + I/O)
  - [go-hep/hepevt](https://github.com/go-hep/hepevt),[go-hep/heppdt](https://github.com/go-hep/heppdt): HEPEVT bindings and HEP particle data table
  - [go-hep/lhef](https://github.com/go-hep/lhef), [go-hep/slha](https://github.com/go-hep/slha): Les Houches Event File format and SUSY Les Houches Accord I/O
  - [go-hep/croot](https://github.com/go-hep/croot): bindings to a subset of ROOT I/O
  - [go-hep/rio](https://github.com/go-hep/rio), [go-hep/sio](https://github.com/go-hep/sio): go-hep record oriented I/O and LCIO I/O

## Conclusions

Don't communicate by sharing memory, share memory by communicating.

Go is great at writing small and large (concurrent) programs.
Also true for science-y programs, even if the amount of HEP-oriented libraries can still be improved.

.image _figs/funfast.svg 320 _

Write your next tool/analysis/simulation/software in [Go](https://golang.org/)?

## Acknowledgements / resources

.link https://tour.golang.org
.link https://talks.golang.org/2012/splash.slide
.link https://talks.golang.org/2012/goforc.slide
.link https://talks.golang.org/2012/waza.slide
.link https://talks.golang.org/2012/concurrency.slide
.link https://talks.golang.org/2013/advconc.slide
.link https://talks.golang.org/2014/gocon-tokyo.slide
.link https://talks.golang.org/2015/simplicity-is-complicated.slide
.link https://talks.golang.org/2016/applicative.slide
.link https://agenda.infn.it/getFile.py/access?contribId=24&sessionId=3&resId=0&materialId=slides&confId=11680
